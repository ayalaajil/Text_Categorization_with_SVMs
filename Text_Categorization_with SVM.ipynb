{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Categorization with SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python modules\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Load data from .csv file\n",
    "############\n",
    "with open('movie_reviews.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file, delimiter=',',quotechar='\"')\n",
    "        \n",
    "    # Initialize lists for data and class labels\n",
    "    data =[]\n",
    "    labels = []\n",
    "    # For each row of the csv file\n",
    "    for row in reader:\n",
    "        # skip missing data\n",
    "        if len(row) < 2:\n",
    "            continue\n",
    "        if row[0] and row[1]:\n",
    "            e=row[0].encode('utf-8')\n",
    "            data.append(e.decode('utf-8'))\n",
    "            y_label = -1 if row[1]=='negative' else 1\n",
    "            labels.append(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Data preprocessing\n",
    "############\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "                 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "                 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "                 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "                 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "                 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "                 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "                 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "                 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "                 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "                 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "                 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "\n",
    "# For each document in the dataset, do the preprocessing\n",
    "for doc_id, text in enumerate(data):\n",
    "    \n",
    "    #\n",
    "    #  ADD YOUR CODE TO THE NEXT BLOCK\n",
    "\n",
    "    # Remove punctuation and lowercase\n",
    "    punctuation = set(string.punctuation)\n",
    "    doc = ''.join ([w for w in text.lower() if w not in punctuation])\n",
    "\n",
    "    # TODO: Add your code here. Store results to a list with name 'doc' \n",
    "        \n",
    "    # Stopword removal\n",
    "    # TODO: Add your code here. Store results to a list with name 'doc'\n",
    "    L = ''.join([w for w in doc if w not in stopwords])\n",
    "    doc=L\n",
    "        \n",
    "    # Stemming\n",
    "    # TODO: Add your code here. Store results to a list with name 'doc'\n",
    "    stemmer=PorterStemmer()\n",
    "    doc=[stemmer.stem(w) for w in doc]\n",
    "        \n",
    "    # Convert list of words to one string\n",
    "    doc = ''.join(w for w in doc)\n",
    "    data[doc_id] = doc   # list data contains the preprocessed documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of TF-IDF matrix  (913, 4844)\n"
     ]
    }
   ],
   "source": [
    "# Part 3: Feature extraction and the TF-IDF matrix\n",
    "#############\n",
    "#\n",
    "#  ADD YOUR CODE HERE\n",
    "#\n",
    "# Create the TF-IFD matrix as described in the lab assignment\n",
    "m=TfidfVectorizer()\n",
    "tfidf_matrix=m.fit_transform(data)\n",
    "tfidf_matrix=tfidf_matrix.toarray()\n",
    "print(\"size of TF-IDF matrix \", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Model learning and prediction\n",
    "#############\n",
    "## Split the data into random train and test subsets. Here we use 40% of the \n",
    "# data for testing\n",
    "data_train,data_test,labels_train,labels_test = train_test_split(tfidf_matrix,labels,test_size=0.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model learning and prediction\n",
    "clf=svm.LinearSVC()\n",
    "y_score=clf.fit(data_train,labels_train)._predict_proba_lr(data_test)\n",
    "labels_pred=clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        15\n",
      "           1       0.96      1.00      0.98       351\n",
      "\n",
      "    accuracy                           0.96       366\n",
      "   macro avg       0.48      0.50      0.49       366\n",
      "weighted avg       0.92      0.96      0.94       366\n",
      "\n",
      "the accuracy is : 0.9590163934426229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayala\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ayala\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ayala\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels_test,labels_pred))\n",
    "print(\"the accuracy is :\",accuracy_score(labels_test,labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aaa47cc248d33b1bf4c9beaeb612c72928cb147969996e2737eac33129a36ab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
